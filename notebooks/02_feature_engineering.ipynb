{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c17377e",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1. Flag de campanha anterior\n",
    "train['foi_contatado_antes'] = (train['pdays'] != -1).astype(int)\n",
    "\n",
    "# 2. Meses de alta conversão (seasonality)\n",
    "high_season_months = ['mar', 'sep', 'oct', 'dec']\n",
    "train['is_high_season'] = train['month'].isin(high_season_months).astype(int)\n",
    "\n",
    "# 3. Bins de balance\n",
    "train['balance_category'] = pd.cut(train['balance'], \n",
    "                                 bins=[-np.inf, 0, 1000, 5000, np.inf],\n",
    "                                 labels=['negative', 'low', 'medium', 'high'])\n",
    "\n",
    "# 4. Bins de age\n",
    "train['age_group'] = pd.cut(train['age'], \n",
    "                          bins=[0, 25, 35, 50, 65, 100],\n",
    "                          labels=['jovem', 'adulto_jovem', 'adulto', 'senior', 'aposentado'])\n",
    "\n",
    "# 5. Intensidade de campanha (normalizado)\n",
    "train['campaign_intensity'] = train['campaign'] + train['previous']\n",
    "\n",
    "# 6. Taxa de sucesso histórico (binária)\n",
    "train['historico_positivo'] = (train['poutcome'] == 'success').astype(int)\n",
    "\n",
    "# 7. Profissões de alta conversão\n",
    "high_conversion_jobs = ['student', 'retired', 'unemployed', 'management']\n",
    "train['job_high_conversion'] = train['job'].isin(high_conversion_jobs).astype(int)\n",
    "\n",
    "# 8. Tem contato efetivo (não é unknown)\n",
    "train['has_effective_contact'] = (train['contact'] != 'unknown').astype(int)\n",
    "\n",
    "# 9. Razão balance/age (capacidade financeira relativa)\n",
    "train['balance_per_age'] = train['balance'] / (train['age'] + 1)\n",
    "\n",
    "# 10. Flag de cliente \"frio\" (muitos contatos sem sucesso)\n",
    "train['cliente_frio'] = ((train['campaign'] > 3) & (train['poutcome'] != 'success')).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173bd4d",
   "metadata": {},
   "source": [
    "# Ajustando Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4c8ae",
   "metadata": {},
   "source": [
    "## Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90616df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined shape: (1000000, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TRAIN_DIR = \"../data/raw/analise-preditiva-de-comportamento-bancario/train.csv\"\n",
    "TEST_DIR = \"../data/raw/analise-preditiva-de-comportamento-bancario/test.csv\"\n",
    "SAMPLE_DIR = \"../data/raw/analise-preditiva-de-comportamento-bancario/sample_submission.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_DIR)\n",
    "test = pd.read_csv(TEST_DIR)\n",
    "sample = pd.read_csv(SAMPLE_DIR)\n",
    "\n",
    "#print(f\"Train shape: {train.shape}\")\n",
    "#print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# Separar target\n",
    "y_train = train['y']\n",
    "X_train = train.drop('y', axis=1)\n",
    "\n",
    "# Concatenar para aplicar transformações uniformemente\n",
    "df_combined = pd.concat([X_train, test], axis=0, ignore_index=True)\n",
    "print(f\"\\nCombined shape: {df_combined.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5dc0a1",
   "metadata": {},
   "source": [
    "## Features Binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24de98f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features binárias criadas:\n",
      "['foi_contatado_antes', 'historico_sucesso', 'historico_failure', 'historico_unknown', 'job_high_conversion', 'has_effective_contact', 'contact_cellular', 'has_default', 'has_housing', 'has_loan', 'no_debt', 'is_single', 'is_married', 'high_education']\n"
     ]
    }
   ],
   "source": [
    "def create_binary_features(df):\n",
    "    \"\"\"Cria features binárias baseadas em insights do EDA\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1.1 Foi contatado anteriormente\n",
    "    df['foi_contatado_antes'] = (df['pdays'] != -1).astype(int)\n",
    "    \n",
    "    # 1.2 Histórico de sucesso em campanhas\n",
    "    df['historico_sucesso'] = (df['poutcome'] == 'success').astype(int)\n",
    "    df['historico_failure'] = (df['poutcome'] == 'failure').astype(int)\n",
    "    df['historico_unknown'] = (df['poutcome'] == 'unknown').astype(int)\n",
    "    \n",
    "    # 1.3 Profissões de alta conversão (>15%)\n",
    "    high_conversion_jobs = ['student', 'retired', 'unemployed', 'management']\n",
    "    df['job_high_conversion'] = df['job'].isin(high_conversion_jobs).astype(int)\n",
    "    \n",
    "    # 1.4 Contato efetivo (não é unknown)\n",
    "    df['has_effective_contact'] = (df['contact'] != 'unknown').astype(int)\n",
    "    df['contact_cellular'] = (df['contact'] == 'cellular').astype(int)\n",
    "    \n",
    "    # 1.5 Situação financeira\n",
    "    df['has_default'] = (df['default'] == 'yes').astype(int)\n",
    "    df['has_housing'] = (df['housing'] == 'yes').astype(int)\n",
    "    df['has_loan'] = (df['loan'] == 'yes').astype(int)\n",
    "    df['no_debt'] = ((df['default'] == 'no') & (df['loan'] == 'no')).astype(int)\n",
    "    \n",
    "    # 1.6 Status civil\n",
    "    df['is_single'] = (df['marital'] == 'single').astype(int)\n",
    "    df['is_married'] = (df['marital'] == 'married').astype(int)\n",
    "    \n",
    "    # 1.7 Educação superior\n",
    "    df['high_education'] = (df['education'].isin(['tertiary', 'unknown'])).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_combined = create_binary_features(df_combined)\n",
    "print(\"Features binárias criadas:\")\n",
    "binary_features = [col for col in df_combined.columns if col.startswith(('foi_', 'historico_', 'job_', 'has_', 'is_', 'contact_', 'no_', 'high_'))]\n",
    "print(binary_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad42ee9",
   "metadata": {},
   "source": [
    "## Features Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3776778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features temporais criadas:\n",
      "['is_high_season', 'is_may', 'quarter', 'day_period', 'inicio_mes', 'fim_mes']\n"
     ]
    }
   ],
   "source": [
    "def create_temporal_features(df):\n",
    "    \"\"\"Cria features baseadas em padrões temporais\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 2.1 Meses de alta conversão (>40% conversão no EDA)\n",
    "    high_season_months = ['mar', 'sep', 'oct', 'dec']\n",
    "    df['is_high_season'] = df['month'].isin(high_season_months).astype(int)\n",
    "    \n",
    "    # 2.2 Mês com pior conversão\n",
    "    df['is_may'] = (df['month'] == 'may').astype(int)\n",
    "    \n",
    "    # 2.3 Trimestres\n",
    "    month_to_quarter = {\n",
    "        'jan': 1, 'feb': 1, 'mar': 1,\n",
    "        'apr': 2, 'may': 2, 'jun': 2,\n",
    "        'jul': 3, 'aug': 3, 'sep': 3,\n",
    "        'oct': 4, 'nov': 4, 'dec': 4\n",
    "    }\n",
    "    df['quarter'] = df['month'].map(month_to_quarter)\n",
    "    \n",
    "    # 2.4 Início/meio/fim do mês\n",
    "    df['day_period'] = pd.cut(df['day'], \n",
    "                               bins=[0, 10, 20, 31], \n",
    "                               labels=[0, 1, 2])  # 0=início, 1=meio, 2=fim\n",
    "    df['day_period'] = df['day_period'].astype(int)\n",
    "    \n",
    "    # 2.5 Início do mês (dias 1-5)\n",
    "    df['inicio_mes'] = (df['day'] <= 5).astype(int)\n",
    "    \n",
    "    # 2.6 Fim do mês (dias 25-31)\n",
    "    df['fim_mes'] = (df['day'] >= 25).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_combined = create_temporal_features(df_combined)\n",
    "print(\"\\nFeatures temporais criadas:\")\n",
    "temporal_features = ['is_high_season', 'is_may', 'quarter', 'day_period', 'inicio_mes', 'fim_mes']\n",
    "print(temporal_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c0523",
   "metadata": {},
   "source": [
    "## Features de Campanha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2949404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features de campanha criadas:\n",
      "['total_contacts', 'contact_frequency', 'cliente_frio', 'cliente_quente', 'cliente_novo', 'pdays_category', 'contato_recente', 'high_campaign_intensity']\n"
     ]
    }
   ],
   "source": [
    "def create_campaign_features(df):\n",
    "    \"\"\"Cria features relacionadas ao histórico de campanhas\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 3.1 Total de contatos (atual + anteriores)\n",
    "    df['total_contacts'] = df['campaign'] + df['previous']\n",
    "    \n",
    "    # 3.2 Frequência de contatos (normalizado)\n",
    "    df['contact_frequency'] = df['campaign'] / (df['campaign'].max() + 1)\n",
    "    \n",
    "    # 3.3 Cliente \"quente\" vs \"frio\"\n",
    "    # Frio: muitos contatos sem sucesso\n",
    "    df['cliente_frio'] = ((df['campaign'] > 3) & (df['poutcome'] != 'success')).astype(int)\n",
    "    \n",
    "    # Quente: poucos contatos com histórico positivo\n",
    "    df['cliente_quente'] = ((df['campaign'] <= 2) & (df['poutcome'] == 'success')).astype(int)\n",
    "    \n",
    "    # 3.4 Cliente virgem (sem histórico)\n",
    "    df['cliente_novo'] = ((df['previous'] == 0) & (df['poutcome'] == 'unknown')).astype(int)\n",
    "    \n",
    "    # 3.5 Tempo desde último contato (categorizado)\n",
    "    # -1 = nunca contatado, 0-30 = recente, 31-180 = médio, >180 = antigo\n",
    "    df['pdays_category'] = pd.cut(df['pdays'], \n",
    "                                    bins=[-2, -1, 30, 180, 999],\n",
    "                                    labels=[0, 1, 2, 3])  # 0=nunca, 1=recente, 2=médio, 3=antigo\n",
    "    df['pdays_category'] = df['pdays_category'].astype(int)\n",
    "    \n",
    "    # 3.6 Recência do contato (se foi contatado)\n",
    "    df['contato_recente'] = ((df['pdays'] > 0) & (df['pdays'] <= 30)).astype(int)\n",
    "    \n",
    "    # 3.7 Intensidade de campanha\n",
    "    df['high_campaign_intensity'] = (df['campaign'] > df['campaign'].median()).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_combined = create_campaign_features(df_combined)\n",
    "print(\"\\nFeatures de campanha criadas:\")\n",
    "campaign_features = ['total_contacts', 'contact_frequency', 'cliente_frio', 'cliente_quente', \n",
    "                     'cliente_novo', 'pdays_category', 'contato_recente', 'high_campaign_intensity']\n",
    "print(campaign_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea190d6",
   "metadata": {},
   "source": [
    "## Features Financeiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904971ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features financeiras criadas:\n",
      "['balance_category', 'balance_negative', 'balance_high', 'balance_zero', 'balance_per_age', 'balance_log', 'total_loans', 'sem_dividas', 'perfil_premium']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_financial_features(df):\n",
    "    \"\"\"Cria features baseadas em variáveis financeiras\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 4.1 Categorização de balance\n",
    "    df['balance_category'] = pd.cut(df['balance'], \n",
    "                                     bins=[-np.inf, 0, 1000, 5000, np.inf],\n",
    "                                     labels=[0, 1, 2, 3])  # 0=negativo, 1=baixo, 2=médio, 3=alto\n",
    "    df['balance_category'] = df['balance_category'].astype(int)\n",
    "    \n",
    "    # 4.2 Flags de balance\n",
    "    df['balance_negative'] = (df['balance'] < 0).astype(int)\n",
    "    df['balance_high'] = (df['balance'] > 5000).astype(int)\n",
    "    df['balance_zero'] = (df['balance'] == 0).astype(int)\n",
    "    \n",
    "    # 4.3 Balance normalizado por idade (capacidade financeira relativa)\n",
    "    df['balance_per_age'] = df['balance'] / (df['age'] + 1)\n",
    "    \n",
    "    # 4.4 Log de balance (para tratar outliers e distribuição)\n",
    "    # Adicionar constante para lidar com valores negativos\n",
    "    df['balance_log'] = np.log1p(df['balance'] + abs(df['balance'].min()) + 1)\n",
    "    \n",
    "    # 4.5 Situação de endividamento geral\n",
    "    df['total_loans'] = df['has_housing'] + df['has_loan'] + df['has_default']\n",
    "    df['sem_dividas'] = (df['total_loans'] == 0).astype(int)\n",
    "    \n",
    "    # 4.6 Perfil financeiro composto\n",
    "    # Alto balance + sem dívidas = perfil \"premium\"\n",
    "    df['perfil_premium'] = ((df['balance'] > df['balance'].median()) & \n",
    "                            (df['sem_dividas'] == 1)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_combined = create_financial_features(df_combined)\n",
    "print(\"\\nFeatures financeiras criadas:\")\n",
    "financial_features = ['balance_category', 'balance_negative', 'balance_high', 'balance_zero',\n",
    "                      'balance_per_age', 'balance_log', 'total_loans', 'sem_dividas', 'perfil_premium']\n",
    "print(financial_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e7147",
   "metadata": {},
   "source": [
    "## Features Demográficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b13fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features demográficas criadas:\n",
      "['age_group', 'is_young', 'is_senior', 'working_age', 'estudante_jovem', 'aposentado_senior', 'high_status', 'poupador_potencial']\n"
     ]
    }
   ],
   "source": [
    "def create_demographic_features(df):\n",
    "    \"\"\"Cria features demográficas\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 5.1 Faixas etárias\n",
    "    df['age_group'] = pd.cut(df['age'], \n",
    "                              bins=[0, 25, 35, 50, 65, 100],\n",
    "                              labels=[0, 1, 2, 3, 4])  # jovem, adulto_jovem, adulto, senior, idoso\n",
    "    df['age_group'] = df['age_group'].astype(int)\n",
    "    \n",
    "    # 5.2 Flags de idade\n",
    "    df['is_young'] = (df['age'] < 30).astype(int)\n",
    "    df['is_senior'] = (df['age'] >= 60).astype(int)\n",
    "    df['working_age'] = ((df['age'] >= 25) & (df['age'] < 65)).astype(int)\n",
    "    \n",
    "    # 5.3 Perfis combinados (idade + profissão)\n",
    "    df['estudante_jovem'] = ((df['job'] == 'student') & (df['age'] < 30)).astype(int)\n",
    "    df['aposentado_senior'] = ((df['job'] == 'retired') & (df['age'] >= 60)).astype(int)\n",
    "    \n",
    "    # 5.4 Perfil socioeconômico (educação + profissão + balance)\n",
    "    high_status_jobs = ['management', 'self-employed', 'entrepreneur']\n",
    "    df['high_status'] = ((df['job'].isin(high_status_jobs)) & \n",
    "                         (df['education'] == 'tertiary')).astype(int)\n",
    "    \n",
    "    # 5.5 Potencial de poupança (balance alto + idade trabalhadora)\n",
    "    df['poupador_potencial'] = ((df['balance'] > df['balance'].median()) & \n",
    "                                 (df['working_age'] == 1)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_combined = create_demographic_features(df_combined)\n",
    "print(\"\\nFeatures demográficas criadas:\")\n",
    "demographic_features = ['age_group', 'is_young', 'is_senior', 'working_age',\n",
    "                        'estudante_jovem', 'aposentado_senior', 'high_status', 'poupador_potencial']\n",
    "print(demographic_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc297a4b",
   "metadata": {},
   "source": [
    "## Features de Interação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218f2f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features de interação criadas:\n",
      "['age_balance_ratio', 'campaign_success_interaction', 'education_job_match', 'contact_timing', 'balance_loan_ratio', 'weighted_history']\n"
     ]
    }
   ],
   "source": [
    "def create_interaction_features(df):\n",
    "    \"\"\"Cria features de interação entre variáveis\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 6.1 Idade x Balance (poder aquisitivo por idade)\n",
    "    df['age_balance_ratio'] = (df['age'] * df['balance']) / 1000\n",
    "    \n",
    "    # 6.2 Campanha x Histórico (efetividade de recontato)\n",
    "    df['campaign_success_interaction'] = df['campaign'] * df['historico_sucesso']\n",
    "    \n",
    "    # 6.3 Educação x Profissão (consistência de perfil)\n",
    "    df['education_job_match'] = ((df['education'] == 'tertiary') & \n",
    "                                  (df['job'].isin(['management', 'technician', 'services']))).astype(int)\n",
    "    \n",
    "    # 6.4 Contato x Mês (timing de contato)\n",
    "    df['contact_timing'] = df['contact_cellular'] * df['is_high_season']\n",
    "    \n",
    "    # 6.5 Balance x Empréstimos (risco financeiro)\n",
    "    df['balance_loan_ratio'] = df['balance'] / (df['total_loans'] + 1)\n",
    "    \n",
    "    # 6.6 Previous x Poutcome (histórico ponderado)\n",
    "    poutcome_weight = {'success': 3, 'failure': -1, 'other': 0, 'unknown': 0}\n",
    "    df['poutcome_numeric'] = df['poutcome'].map(poutcome_weight)\n",
    "    df['weighted_history'] = df['previous'] * df['poutcome_numeric']\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_combined = create_interaction_features(df_combined)\n",
    "print(\"\\nFeatures de interação criadas:\")\n",
    "interaction_features = ['age_balance_ratio', 'campaign_success_interaction', 'education_job_match',\n",
    "                        'contact_timing', 'balance_loan_ratio', 'weighted_history']\n",
    "print(interaction_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29bed2",
   "metadata": {},
   "source": [
    "## Encoding de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c29f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emaci\\AppData\\Local\\Temp\\ipykernel_49924\\1372905346.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['job_encoded'].fillna(job_means.mean(), inplace=True)\n",
      "C:\\Users\\emaci\\AppData\\Local\\Temp\\ipykernel_49924\\1372905346.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['education_encoded'].fillna(education_means.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding aplicado às variáveis categóricas\n"
     ]
    }
   ],
   "source": [
    "def encode_categorical_features(df, target=None, train_size=None):\n",
    "    \"\"\"\n",
    "    Aplica encoding nas variáveis categóricas\n",
    "    - Target Encoding para alta cardinalidade\n",
    "    - Label Encoding para ordinais\n",
    "    - One-Hot para baixa cardinalidade\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 7.1 Label Encoding para month (ordem temporal)\n",
    "    month_order = {'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "                   'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "    df['month_encoded'] = df['month'].map(month_order)\n",
    "    \n",
    "    # 7.2 Target Encoding para job e education (alta cardinalidade)\n",
    "    # Apenas se tivermos o target (durante treino)\n",
    "    if target is not None and train_size is not None:\n",
    "        # Calcular médias no conjunto de treino\n",
    "        df_train = df.iloc[:train_size].copy()\n",
    "        df_train['target'] = target\n",
    "        \n",
    "        # Job\n",
    "        job_means = df_train.groupby('job')['target'].mean()\n",
    "        df['job_encoded'] = df['job'].map(job_means)\n",
    "        df['job_encoded'].fillna(job_means.mean(), inplace=True)\n",
    "        \n",
    "        # Education\n",
    "        education_means = df_train.groupby('education')['target'].mean()\n",
    "        df['education_encoded'] = df['education'].map(education_means)\n",
    "        df['education_encoded'].fillna(education_means.mean(), inplace=True)\n",
    "        \n",
    "    else:\n",
    "        # Se não tiver target, usar label encoding simples\n",
    "        le_job = LabelEncoder()\n",
    "        le_education = LabelEncoder()\n",
    "        df['job_encoded'] = le_job.fit_transform(df['job'])\n",
    "        df['education_encoded'] = le_education.fit_transform(df['education'])\n",
    "    \n",
    "    # 7.3 One-Hot Encoding para variáveis de baixa cardinalidade\n",
    "    # Marital\n",
    "    df['marital_single'] = (df['marital'] == 'single').astype(int)\n",
    "    df['marital_married'] = (df['marital'] == 'married').astype(int)\n",
    "    df['marital_divorced'] = (df['marital'] == 'divorced').astype(int)\n",
    "    \n",
    "    # Contact (já fizemos algumas flags, completar)\n",
    "    df['contact_telephone'] = (df['contact'] == 'telephone').astype(int)\n",
    "    df['contact_unknown'] = (df['contact'] == 'unknown').astype(int)\n",
    "    \n",
    "    # Poutcome (já temos flags, adicionar other)\n",
    "    df['poutcome_other'] = (df['poutcome'] == 'other').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar encoding\n",
    "df_combined = encode_categorical_features(df_combined, target=y_train, train_size=len(X_train))\n",
    "print(\"\\nEncoding aplicado às variáveis categóricas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52228b26",
   "metadata": {},
   "source": [
    "## Normalização (depende do modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0ad2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para modelos lineares\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalize_features(df, train_size, features_to_normalize=None):\n",
    "    \"\"\"\n",
    "    Normaliza features numéricas usando StandardScaler\n",
    "    Ajusta no train e transforma train+test\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    if features_to_normalize is None:\n",
    "        # Features numéricas que se beneficiam de normalização\n",
    "        features_to_normalize = [\n",
    "            'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous',\n",
    "            'balance_per_age', 'age_balance_ratio', 'balance_loan_ratio'\n",
    "        ]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit apenas no train\n",
    "    scaler.fit(df.iloc[:train_size][features_to_normalize])\n",
    "    \n",
    "    # Transform em train+test\n",
    "    df[features_to_normalize] = scaler.transform(df[features_to_normalize])\n",
    "    \n",
    "    return df, scaler\n",
    "\n",
    "# Guardar versão sem normalização (para tree-based models)\n",
    "df_combined_original = df_combined.copy()\n",
    "\n",
    "# Versão normalizada (para modelos lineares, se necessário)\n",
    "# df_combined_normalized, scaler = normalize_features(df_combined, len(X_train))\n",
    "# print(\"\\nNormalização aplicada (versão separada criada)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138ce79",
   "metadata": {},
   "source": [
    "## Seleção de Features e Preparação Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2d1425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape após feature engineering: (1000000, 68)\n",
      "Número de features criadas: 61\n",
      "\n",
      "Train processed shape: (750000, 69)\n",
      "Test processed shape: (250000, 68)\n",
      "\n",
      "Valores faltantes no train: 0\n",
      "Valores faltantes no test: 0\n"
     ]
    }
   ],
   "source": [
    "# Features originais a remover (já foram transformadas)\n",
    "features_to_drop = ['job', 'marital', 'education', 'default', 'housing', 'loan', \n",
    "                    'contact', 'month', 'poutcome', 'poutcome_numeric']\n",
    "\n",
    "# Remover features originais categóricas\n",
    "df_final = df_combined.drop(columns=features_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\nShape após feature engineering: {df_final.shape}\")\n",
    "print(f\"Número de features criadas: {df_final.shape[1] - len(X_train.columns) + len(features_to_drop)}\")\n",
    "\n",
    "# Separar novamente em train e test\n",
    "X_train_processed = df_final.iloc[:len(X_train)].copy()\n",
    "X_test_processed = df_final.iloc[len(X_train):].copy()\n",
    "\n",
    "# Adicionar o target de volta ao train\n",
    "X_train_processed['y'] = y_train.values\n",
    "\n",
    "print(f\"\\nTrain processed shape: {X_train_processed.shape}\")\n",
    "print(f\"Test processed shape: {X_test_processed.shape}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"\\nValores faltantes no train: {X_train_processed.isnull().sum().sum()}\")\n",
    "print(f\"Valores faltantes no test: {X_test_processed.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196d336",
   "metadata": {},
   "source": [
    "## Salvar Dados Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b990e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dados processados salvos em data/processed/\n",
      "\n",
      "Arquivos criados:\n",
      "- train_processed.csv\n",
      "- test_processed.csv\n",
      "\n",
      "Total de features: 68\n",
      "\n",
      "Primeiras 20 features:\n",
      "['id', 'age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous', 'foi_contatado_antes', 'historico_sucesso', 'historico_failure', 'historico_unknown', 'job_high_conversion', 'has_effective_contact', 'contact_cellular', 'has_default', 'has_housing', 'has_loan', 'no_debt', 'is_single']\n"
     ]
    }
   ],
   "source": [
    "# Salvar datasets processados\n",
    "X_train_processed.to_csv('../data/processed/train_processed.csv', index=False)\n",
    "X_test_processed.to_csv('../data/processed/test_processed.csv', index=False)\n",
    "\n",
    "print(\"\\nDados processados salvos em data/processed/\")\n",
    "print(\"\\nArquivos criados:\")\n",
    "print(\"- train_processed.csv\")\n",
    "print(\"- test_processed.csv\")\n",
    "\n",
    "# Mostrar lista de todas as features criadas\n",
    "all_features = X_train_processed.drop('y', axis=1).columns.tolist()\n",
    "print(f\"\\nTotal de features: {len(all_features)}\")\n",
    "print(\"\\nPrimeiras 20 features:\")\n",
    "print(all_features[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f1770",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a72b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESUMO DA FEATURE ENGINEERING\n",
      "======================================================================\n",
      "\n",
      "Features Criadas por Categoria:\n",
      "  • Binárias (flags): 14\n",
      "  • Temporais: 6\n",
      "  • Campanha: 8\n",
      "  • Financeiras: 9\n",
      "  • Demográficas: 8\n",
      "  • Interações: 6\n",
      "\n",
      "Total de features: 68 (excluindo target)\n",
      "Features originais: 17\n",
      "Features novas: 51\n",
      "\n",
      "Decisões Importantes:\n",
      "  • Duration: MANTIDA\n",
      "  • Target Encoding: Aplicado em job e education\n",
      "  • Normalização: Preparada mas não aplicada (usar para Linear Models)\n",
      "  • Dados salvos: ../data/processed/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMO DA FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFeatures Criadas por Categoria:\")\n",
    "print(f\"  • Binárias (flags): {len(binary_features)}\")\n",
    "print(f\"  • Temporais: {len(temporal_features)}\")\n",
    "print(f\"  • Campanha: {len(campaign_features)}\")\n",
    "print(f\"  • Financeiras: {len(financial_features)}\")\n",
    "print(f\"  • Demográficas: {len(demographic_features)}\")\n",
    "print(f\"  • Interações: {len(interaction_features)}\")\n",
    "\n",
    "print(f\"\\nTotal de features: {X_train_processed.shape[1] - 1} (excluindo target)\")\n",
    "print(f\"Features originais: {X_train.shape[1]}\")\n",
    "print(f\"Features novas: {X_train_processed.shape[1] - 1 - X_train.shape[1]}\")\n",
    "\n",
    "print(\"\\nDecisões Importantes:\")\n",
    "print(\"  • Duration: MANTIDA\")\n",
    "print(\"  • Target Encoding: Aplicado em job e education\")\n",
    "print(\"  • Normalização: Preparada mas não aplicada (usar para Linear Models)\")\n",
    "print(\"  • Dados salvos: ../data/processed/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
